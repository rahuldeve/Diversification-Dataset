Hash	  tables	  (continued)	  

What	  are	  the	  limitations	  of	  using	  a	  really	  big	  array	  to	  store	  student	  object?	  
	  

	  	  	  
	  Recall:	  Suppose	  we	  want	  maintain	  a	  set	  of	  students,	  where	  a	  student	  object	  has	  a	  
name	  and	  9-digit	  id,	  and	  we	  want	  to	  be	  able	  to	  access	  students	  quickly.	  
	  
1. Need	  a	  way	  to	  generate	  a	  unique	  integer	  from	  object	  for	  the	  index	  	  
	  
Eg,	  the	  9-digit	  student	  id.	  
2. Need	  a	  huge	  amount	  of	  memory	  (dependent	  on	  the	  range	  of	  possible	  values	  for	  
the	  integer	  index)	  
3. Really	  slow	  to	  iterate	  through	  all	  the	  objects	  
1. Need	  a	  way	  to	  generate	  an	  integer	  from	  object	  for	  the	  index	  	  
Eg,	  The	  last	  two	  digits	  of	  the	  student	  id	  
2. Collisions	  are	  always	  possible	  and	  cannot	  be	  avoided	  (the	  pigeon	  hole	  
principal).	  
	  	  
Hash	  table	  	  The	  data	  structure	  we	  are	  discussing	  
	  
Hash	  function	  	  a	  way	  to	  compute	  an	  index	  into	  the	  hash	  table	  from	  an	  object.	  
	  
Load	  factor	  	  (number	  of	  elements)	  /	  (size	  of	  the	  table)	  
	  
Collision	  	  2	  or	  more	  elements	  hash	  to	  the	  same	  index	  
	  
Bucket	  	  	  "container"	  for	  all	  the	  elements	  that	  hash	  to	  an	  index	  
	  	  

What	  are	  the	  limitations	  of	  using	  a	  medium	  big	  array	  to	  store	  student	  object?	  

	  

Terminology	  

	  

Implementation	  

	  

What	  data	  structures	  should	  we	  use	  to	  implement	  a	  hash	  table?	  
	  

Table	  	  Use	  array	  of	  buckets,	  an	  array	  is	  the	  simplest	  and	  most	  efficient	  
	  
Bucket	  	  -	  It's	  a	  set.	  	  What	  implementation	  of	  a	  Set?	  
	  
	  	  	  	  
	  	  	  	  	  	  	  	  	  	  Hash	  table?	  	  No.	  
o  What	  could	  we	  use	  for	  the	  hash	  function,	  when	  the	  current	  one	  just	  
failed?	  	  
	  
Binary	  Search	  Tree?	  	  No.	  
	  
o  Overkill	  We	  expect	  the	  buckets	  will	  only	  a	  few	  elements	  in	  a	  bucket	  
o  Requires	  Comparable	  (hashing	  does	  not	  need	  Comparable	  on	  its	  own)	  
	  
	  	  	  	  	  	  	  	  	  	  	  linked	  list	  of	  nodes?	  Yes!	  
o  Simple	  	  easy	  to	  implement	  
o  Expandable	  as	  needed	  
o  Empty	  linked	  lists	  (null)	  need	  use	  no	  additional	  storage	  
o  Elements	  don't	  need	  to	  be	  Comparable	  
	  

	  

	  	  
What	  is	  the	  expected	  size	  of	  a	  bucket?	  The	  load	  factor	  
	  
What	  is	  a	  good	  load	  factor?	  	  	  
A	  small	  constant	  so	  that	  the	  linked	  lists	  stay	  short,	  even	  longest	  ones.	  (Java	  uses	  a	  
default	  value	  of	  0.75)	  

	  

How	  much	  bigger	  should	  we	  create	  the	  array?	  

What	  if	  the	  load	  factor	  gets	  large?	  
	  

	  
Trade-off:	  Space	  vs	  time	  
 The	  probability	  of	  a	  collision	  increase	  as	  the	  load	  factor	  increases.	  
 Increase	  array	  size	  	  fewer	  collision	  	  faster	  contains,	  add,	  remove	  
 Decrease	  array	  size	  	  more	  collisions	  	  -	  slower	  contains,	  add,	  remove	  
	  
	  
Then	  the	  linked	  lists	  can	  get	  long,	  and	  expected	  run	  times	  go	  up.	  Even	  worse,	  
the	  longest	  linked	  lists	  may	  be	  much	  longer	  the	  average	  length.	  
	  	   What	  can	  we	  do?	  
Solution:	  Create	  a	  larger	  table	  
	  
	  
Can	  we	  just	  copy	  the	  elements	  from	  the	  original	  table	  to	  a	  new	  table?	  No!	  
	   We	  need	  to	  reinsert	  each	  element	  of	  the	  old	  table	  to	  the	  new	  table	  using	  
a	  new	  hash	  function.	  
	  
	  Approximately	  twice	  the	  size	  (adds	  only	  O(1)	  amortize	  time)	  
	  	  	  Worst-case	  runtimes	  for	  Set/Map	  implementations:	  
	  
	  
contains	  
restriction	  
	  
add/remove	  
O(n)	  
	  
O(n)	  
Unsorted	  array	  
O(n)	  
	  
Unsorted	  linked	  list	  
O(n)	  
O(log	  n)	  
Comparable	  
Sorted	  array	  
O(n)	  
O(n)	  
Comparable	  
O(n)	  
Sorted	  linked	  list	  
O(n)	  
	  
Binary	  tree	  
O(n)	  
O(n)	  
Comparable	  
Binary	  search	  tree	  
O(n)	  
O(log	  n)	  
Balance	  BST	  
O(log	  n)	  
Comparable	  
Need	  valid	  hash	  
O(1)	  
O(1)	  	  
Hash	  table	  -	  expected	  
function	  
O(n)	  
Hash	  table	  	  worst-case	  
O(n)	  
	  	  	  One	  bucket	  
	  	  
Javas	  HashSet	  &	  HashMap	  	  
 These	  classes	  use	  separate	  chaining	  with	  a	  default	  load	  factor	  of	  0.75.	  
 They	  start	  with	  the	  initial	  capacity	  of	  16	  (or	  what	  is	  specified	  in	  the	  
constructor)	  
 Doubles	  the	  array	  when	  it	  reaches	  the	  load	  factor.	  
 The	  order	  the	  set(keySet)	  iterator	  returns	  the	  elements(keys)	  is	  arbitrary,	  and	  
can	  change	  as	  the	  set(map)	  size	  changes.	  

