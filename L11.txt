Lecture 11: Dynamic Progamming
CLRS Chapter 15
Outline of this section

Introduction to Dynamic programming;
a method for solving optimization problems.

Dynamic programming vs. Divide and Conquer

A few examples of Dynamic programming
â€“ the 0-1 Knapsack Problem
â€“ Chain Matrix Multiplication
â€“ All Pairs Shortest Path
â€“ The Floyd Warshall Algorithm: Improved All
Pairs Shortest Path
1

Recalling Divide-and-Conquer

1. Partition the problem into particular subproblems.

2. Solve the subproblems.

3. Combine the solutions to solve the original one.

Remark: In the examples we saw the subproblems
were usually independent, i.e. they did not call the
same subsubproblems. If the subsubproblems were
not independent, then D&C could be resolving many
of the same problems many times. Thus, it does more
work than necessary!
Dynamic programming (DP) solves every subsubproblem exactly once, and is therefore more efficient in
those cases where the subsubproblems are not indepndent.
2

The Intuition behind Dynamic Programming
Dynamic programming is a method for solving
optimization problems.
The idea: Compute the solutions to the subsub-problems
once and store the solutions in a table, so that they
can be reused (repeatedly) later.
Remark: We trade space for time.

3

0-1 Knapsack Problem
Informal Description: We have items. Let  denote the value of the  -th item, and let   denote the
weight of the  -th item. Suppose you are given a knapsack capable of holding total weight  .
Our goal is to use the knapsack to carry items, such
that the total values are maximum; we want to find a
subset of items to carry such that
The total weight is at most  .
The total value of the items is as large as possible.

We cannot take parts of items, it is the whole item or
nothing. (This is why it is called 0-1.)
How should we select the items?
4

0-1 Knapsack Problem
Formal description:
Given 
 , and two -tuples of positive numbers



 	


 

and



    


 

we wish to determine the subset
  



  (of items to carry) that

maximizes
subject to

!"

!"
 $#

 
 


Remark: This is an optimization problem. The Brute

Force solution is to try all   possible subsets .
Question:Is there a better way?
Yes. Dynamic Programming!
5

General Schema of a DP Solution

Step1: Structure: Characterize the structure of an
optimal solution by showing that it can be decomposed into optimal subproblems

Step2: Recursively define the value of an optimal
solution by expressing it in terms of optimal so
lutions for smaller problems (usually using
and/or  ).

Step 3: Bottom-up computation: Compute the value
of an optimal solution in a bottom-up fashion by
using a table structure.

Step 4: Construction of optimal solution: Construct
an optimal solution from computed information.
6

Remarks on the Dynamic Programming Approach

Steps 1-3 form the basis of a dynamic-programming
solution to a problem.

Step 4 can be omitted if only the value of an optimal solution is required.

7

Developing a DP Algorithm for Knapsack
Step 1: Decompose the problem into smaller
problems.
We construct an array   
 
  
 
   .

#  #
For
, and  #  #  , the entry
     will store the maximum
 (combined)
value of any subset of items   


   of (combined) weight at most  .
That is

 	
  

   
"

     !!"! $#%




&

 '(
)

If we can compute all the entries of this array, then
the array entry     will contain the solution
to our problem.



Note: In what follows we will say that is a solu   



   and * + "  + #
tion for      if

 and that is an optimal solution for      if
is a solution and * + "  + ,
    

8

Developing a DP Algorithm for Knapsack
Step 2: Recursively define the value of an optimal
solution in terms of solutions to smaller problems.

Initial Settings: Set





  

 ,
 ,


for  #  #
for    ,





,

no item
illegal





Recursive Step: Use

    ,
for



#  #







, #



#  .





    



   

Intuitively, an optimal solution would either choose item
 is or not choose item  .

9

Developing a DP Algorithm for Knapsack
Step 3: Bottom-up computation of
(using iteration, not recursion).
Bottom:



 ,



   

 for all  #  #  .

Bottom-up computation: Computing the table using

    ,



 





1
0

2
0



 







   

row by row.
V[i,w] w=0
i= 0
0

3
0

...
...

... W
... 0

bottom

1
2
..
.
n
up
10

Example of the Bottom-up computation

,

Let 



 and


1
10
5

 

   

 
1
2
3
4

 
0
0
0
0
0

1
0
0
0
0
0

2
0
0
0
0
0

3
0
0
0
0
50

Remarks:

2
3
4
40 30 50
4
6
3
4
0
0
40
40
50

   
 


5
0
10
40
40
50

6
0
10
40
40
50

7
0
10
40
40
90

8
0
10
40
40
90

9
0
10
50
50
90

10
0
10
50
70
90



The final output is


The method described does
not tell which subset gives the

in this example).
optimal solution. (It is 



.

  #

11

The Dynamic Programming Algorithm
KnapSack(




    

)

  to )   	 
 ;
  to&  )
   to )
    
$
  )  %      	
     
      	 
else
  $
    	
 ;
    
 ;
return
for (
for (
for (
if (



Time complexity: Clearly,
	



   
 
$# ;

  .

12

Constructing the Optimal Solution
The algorithm for computing      described in
the previous slide does not record which subset
of items gives the optimal solution.

To compute the actual subset, we can add an
auxiliary boolean array       which is 1 if we
decide to take the  -th file in      and 0 otherwise.
Question: How do we use all the values       to

determine the subset of files having the maximum
computing time?

13

Constructing the Optimal Solution
Question: How do we use the values        to

determine the subset of items having the maximum
computing time?



If keep[   ] is 1, then
. We can now repeat

this argument for keep[

  ].

If keep[   ] is 0, the
and we repeat the argu
ment for keep[
  ].






Therefore, the following partial program will output the

elements of :


,



;

for (  ,
downto 1)

if (keep     , ,
)




output i;




,





 ;
14

The Complete Algorithm for the Knapsack Problem
KnapSack(




    

)

  	
 ;
&
  
  
 
 
 

   	      
 
     	 
 ))
 	
    
       	      
 
 ;
  
  ;
keep


 


for (
to )


for (
to  )
for (
to )
if (( 
) and (

else




 	
     	 
 ;

keep  

;







;

 downto
for (
1)

if (keep 





return

  
  

output

 i;





   
;



)

  
 ;

15

Dynamic Programming vs. Divide-and-Conquer
The Dynamic Programming algorithm developed runs
in 	    time.
We started by deriving a recurrence relation for solving the problem

    ,
    ,












 





 



Question: why canâ€™t we simply write a top-down divideand-conquer algorithm based on this recurrence?
Answer: we could, but it could run in time
  
since it might have to recompute the same values
many times.
Dynamic programming saves us from having to recompute previously calculated subsolutions!

16

Final Comment
Divide-and-Conquer works Top-Down.
Dynamic programming works Bottom-Up.

17

